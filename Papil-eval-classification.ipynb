{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "# from torchvision import models, transforms\n",
    "# import sys\n",
    "# import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "# import torch.functional as F\n",
    "import numpy as np\n",
    "clear_output()\n",
    "# import glob\n",
    "from utils import *\n",
    "from datetime import date\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from constants import mean, std\n",
    "from PapilledemaLoader import PapilledemaDataset, PapilSeverityDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 ['0', '1', '2', '3', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/mnt/c/Users/PCM/Dropbox/chla_fundus_croped/severity'\n",
    "image_datasets = {x: PapilledemaDataset(data_dir=data_dir, phase=x) for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val',  'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load simclr resnet\n"
     ]
    }
   ],
   "source": [
    "# # pretrain_mode = 'ConPro' #'\n",
    "\n",
    "\n",
    "# # Load from ConPrO weights\n",
    "# bestsmodel = SeverityModel().to(device)\n",
    "# state_dict = torch.load('./pretrained/best-smodel50-wofreeze-2024-03-10.pt')\n",
    "# bestsmodel.load_state_dict(state_dict)\n",
    "# bestsmodel.bestsimese50simclr.cnn1.fc = torch.nn.Sequential(*(list(bestsmodel.bestsimese50simclr.cnn1.fc)+list(bestsmodel.bestsimese50simclr.cnn1.fc2)))\n",
    "# torch.save(bestsmodel.bestsimese50simclr.cnn1.state_dict(), f'./pretrained/pretrained-resnet50-ConPro.pt')\n",
    "# # Load from SupCon-2 weights\n",
    "# smodel = SeverityModel(path2pretrained='./pretrained/best-contrastive50-2024-03-10.pt').to(device)\n",
    "# torch.save(smodel.bestsimese50simclr.cnn1.state_dict(), f'./pretrained/pretrained-resnet50-SupCon.pt')\n",
    "# # Load from SupCon-5 weights\n",
    "smodel5 = SeverityModel(path2pretrained='./pretrained/best-multiclass-contrastive50-2024-03-18-latest.pt').to(device)\n",
    "torch.save(smodel5.bestsimese50simclr.cnn1.state_dict(), f'./pretrained/pretrained-resnet50-SupCon5.pt')\n",
    "# # Load from ImagesNet weights\n",
    "# # Load from Simclr weights\n",
    "# simclrweight = get_feature_extractor(feature_extractor='resnet50', cotrain=False, simclr='/mnt/c/Users/PCM/Dropbox/pretrained/SimCLR/checkpoint_0050.pth.tar')\n",
    "# torch.save(simclrweight.state_dict(), f'./pretrained/pretrained-resnet50-SimCLR.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Run from here to keep same dataset randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_mode = 'SimCLR'\n",
    "\n",
    "clf_model = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "clf_model.load_state_dict(torch.load(f'./pretrained/pretrained-resnet50-{pretrain_mode}.pt'), strict=False)\n",
    "clf_model.fc = nn.Sequential(torch.nn.Linear(2048, 1000),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Dropout(0.1),\n",
    "                                torch.nn.Linear(1000, 256),\n",
    "                                # torch.nn.Linear(256, 256),\n",
    "                                # torch.nn.ReLU(),\n",
    "                                # torch.nn.Dropout(0.1),\n",
    "                                # torch.nn.Linear(256, 256),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Dropout(0.1),\n",
    "                                torch.nn.Linear(256, len(class_names)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31       1.72222222 1.29166667 1.19230769 2.58333333 5.16666667]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "y = np.array(list([sample[1] for sample in image_datasets['test'].samples]))\n",
    "class_weights=compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)\n",
    "print(class_weights)\n",
    "clf_model = clf_model.to(device)\n",
    "momentum = 0.9\n",
    "lr = 0.01\n",
    "optimizer_ft = optim.SGD([{'params': clf_model.fc[:].parameters()}], lr=lr, momentum=momentum)\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.5)\n",
    "\n",
    "for param in clf_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in clf_model.fc[:].parameters():\n",
    "    param.requires_grad = True\n",
    "# for param in clf_model.fc[8:].parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in clf_model.fc.parameters():\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0 With LR 0.01 training acc:  0.13561847988077497 Val acc:  0.10588235294117647 traning loss:  1.750026046963278\n",
      "E1 With LR 0.01 training acc:  0.13710879284649777 Val acc:  0.11764705882352941 traning loss:  1.6785133734189985\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n\u001b[1;32m     13\u001b[0m optimizer_ft\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mclf_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/torchvision/models/resnet.py:274\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m--> 274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/torchvision/models/resnet.py:150\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    147\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m    148\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m--> 150\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m    152\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# bestmodel = siamese50simclr\n",
    "valaccmax = 0\n",
    "for e in range(50):\n",
    "    training_acc = 0\n",
    "    val_acc = 0\n",
    "    training_loss_test = 0.0\n",
    "\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        clf_model.train()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ft.zero_grad()\n",
    "\n",
    "        outputs = clf_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        training_loss_test += loss.item() * inputs.size(0)\n",
    "        training_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "        clf_model.eval()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = clf_model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "        val_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "    if(e > 8 and val_acc >= valaccmax):\n",
    "        valaccmax = val_acc\n",
    "        torch.save(clf_model.state_dict(), f'./pretrained/best-mutilclass-siamese50-{pretrain_mode}.pt')\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"E{e} With LR {optimizer_ft.param_groups[0]['lr']} training acc: \", training_acc.detach().cpu().numpy() / dataset_sizes['train'], \"Val acc: \", val_acc.detach().cpu().numpy() / dataset_sizes['val'], \"traning loss: \", training_loss_test / dataset_sizes['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=1000, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel = models.resnet50(weights='ResNet50_Weights.DEFAULT')#get_feature_extractor(feature_extractor='resnet50', cotrain=False)#, simclr='/mnt/c/Users/PCM/Documents/GitHub/pseudopapill/SimCLR/runs/Oct29_21-00-13_DESKTOP-404G4HS/checkpoint_95_29102023.pth.tar')\n",
    "\n",
    "bestmodel.fc = nn.Sequential(torch.nn.Linear(2048, 1000),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Dropout(0.1),\n",
    "                                torch.nn.Linear(1000, 256),\n",
    "                                # torch.nn.Linear(256, 256),\n",
    "                                # torch.nn.ReLU(),\n",
    "                                # torch.nn.Dropout(0.1),\n",
    "                                # torch.nn.Linear(256, 256),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Dropout(0.1),\n",
    "                                torch.nn.Linear(256, len(class_names)))\n",
    "bestmodel.load_state_dict(torch.load(f'./pretrained/best-mutilclass-siamese50-{pretrain_mode}.pt'))\n",
    "bestmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = 0\n",
    "predlist = []\n",
    "labelist = []\n",
    "problist = []\n",
    "# test_embeddings = torch.zeros((0, 2048))\n",
    "sedis = 0\n",
    "# fextractor = torch.nn.Sequential(*(list(clf_model.children())[:-1]))\n",
    "\n",
    "for inputs, labels in dataloaders['test']:\n",
    "    bestmodel.eval()\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bestmodel(inputs)\n",
    "        # emb = fextractor(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        # loss = loss_fn(outputs, labels)\n",
    "        sedis = sedis + torch.sum(torch.exp(torch.abs(labels - torch.max(outputs, 1)[1])))\n",
    "    problist.append(outputs[:,1].detach().cpu().numpy())\n",
    "    labelist.append(labels.detach().cpu().numpy()*1)\n",
    "    predlist.append(preds.detach().cpu().numpy())\n",
    "    # test_embeddings  = torch.cat((test_embeddings, emb.detach().cpu().flatten().unsqueeze(0)), axis=0)\n",
    "    test_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "labelist = np.concatenate(labelist).ravel()\n",
    "problist = np.concatenate(problist).ravel()\n",
    "predlist = np.concatenate(predlist).ravel()\n",
    "# test_embeddings = np.array(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.5562, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sedis/dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.594     0.760     0.667        50\n",
      "           1      0.222     0.222     0.222         9\n",
      "           2      0.400     0.167     0.235        12\n",
      "           3      0.333     0.231     0.273        13\n",
      "           4      0.500     0.500     0.500         6\n",
      "           5      0.000     0.000     0.000         3\n",
      "\n",
      "    accuracy                          0.516        93\n",
      "   macro avg      0.342     0.313     0.316        93\n",
      "weighted avg      0.471     0.516     0.481        93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongn/miniconda3/envs/xai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hongn/miniconda3/envs/xai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hongn/miniconda3/envs/xai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labelist, predlist, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(labelist, predlist)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run per epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_epoch(pretrain_mode = 'ConPro'):\n",
    "    pretrain_mode = pretrain_mode\n",
    "\n",
    "    data_dir = '/mnt/c/Users/PCM/Dropbox/chla_fundus_croped/severity'\n",
    "    image_datasets = {x: PapilledemaDataset(data_dir=data_dir, phase=x) for x in ['train', 'val', 'test']}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4)\n",
    "                for x in ['train', 'val', 'test']}\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val',  'test']}\n",
    "    class_names = image_datasets['train'].classes\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # print(device, class_names)\n",
    "\n",
    "    clf_model = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "    if(pretrain_mode != 'ImageNet'):\n",
    "        clf_model.load_state_dict(torch.load(f'./pretrained/pretrained-resnet50-{pretrain_mode}.pt'), strict=False)\n",
    "    clf_model.fc = nn.Sequential(torch.nn.Linear(2048, 1000),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    torch.nn.Dropout(0.1),\n",
    "                                    torch.nn.Linear(1000, 256),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    torch.nn.Dropout(0.1),\n",
    "                                    torch.nn.Linear(256, len(class_names)))\n",
    "\n",
    "    class_weights= [0.31,       1.72222222, 1.29166667, 1.19230769, 2.58333333, 5.16666667]\n",
    "    # print(class_weights)\n",
    "    clf_model = clf_model.to(device)\n",
    "    momentum = 0.9\n",
    "    lr = 0.01\n",
    "    optimizer_ft = optim.SGD([{'params': clf_model.fc[:].parameters()}], lr=lr, momentum=momentum)\n",
    "    class_weights=torch.tensor(class_weights,dtype=torch.float).to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.5)\n",
    "\n",
    "    for param in clf_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in clf_model.fc[:].parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    valaccmax = 0\n",
    "    for e in range(50):\n",
    "        training_acc = 0\n",
    "        val_acc = 0\n",
    "        training_loss_test = 0.0\n",
    "\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            clf_model.train()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer_ft.zero_grad()\n",
    "\n",
    "            outputs = clf_model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_ft.step()\n",
    "            training_loss_test += loss.item() * inputs.size(0)\n",
    "            training_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            clf_model.eval()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = clf_model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "\n",
    "            val_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "        if(e > 8 and val_acc >= valaccmax):\n",
    "            valaccmax = val_acc\n",
    "            torch.save(clf_model.state_dict(), f'./pretrained/best-mutilclass-siamese50-{pretrain_mode}.pt')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    bestmodel = models.resnet50(weights='ResNet50_Weights.DEFAULT')#get_feature_extractor(feature_extractor='resnet50', cotrain=False)#, simclr='/mnt/c/Users/PCM/Documents/GitHub/pseudopapill/SimCLR/runs/Oct29_21-00-13_DESKTOP-404G4HS/checkpoint_95_29102023.pth.tar')\n",
    "    bestmodel.fc = nn.Sequential(torch.nn.Linear(2048, 1000),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    torch.nn.Dropout(0.1),\n",
    "                                    torch.nn.Linear(1000, 256),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    torch.nn.Dropout(0.1),\n",
    "                                    torch.nn.Linear(256, len(class_names)))\n",
    "    bestmodel.load_state_dict(torch.load(f'./pretrained/best-mutilclass-siamese50-{pretrain_mode}.pt'))\n",
    "    bestmodel.to(device)\n",
    "\n",
    "    test_acc = 0\n",
    "    predlist = []\n",
    "    labelist = []\n",
    "    problist = []\n",
    "    # test_embeddings = torch.zeros((0, 2048))\n",
    "    sedis = 0\n",
    "    # fextractor = torch.nn.Sequential(*(list(clf_model.children())[:-1]))\n",
    "\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        bestmodel.eval()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = bestmodel(inputs)\n",
    "            # emb = fextractor(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            # loss = loss_fn(outputs, labels)\n",
    "            sedis = sedis + torch.sum(torch.exp(torch.abs(labels - torch.max(outputs, 1)[1])))\n",
    "        problist.append(outputs[:,1].detach().cpu().numpy())\n",
    "        labelist.append(labels.detach().cpu().numpy()*1)\n",
    "        predlist.append(preds.detach().cpu().numpy())\n",
    "        # test_embeddings  = torch.cat((test_embeddings, emb.detach().cpu().flatten().unsqueeze(0)), axis=0)\n",
    "        test_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "    labelist = np.concatenate(labelist).ravel()\n",
    "    problist = np.concatenate(problist).ravel()\n",
    "    predlist = np.concatenate(predlist).ravel()\n",
    "    return sedis/dataset_sizes['test'], f1_score(labelist, predlist, average='weighted'), f1_score(labelist, predlist, average='macro')\n",
    "    # print('MAEE', sedis/dataset_sizes['test'])\n",
    "    # print('weight F1', f1_score(labelist, predlist, average='weighted'))\n",
    "    # print('macro F1', f1_score(labelist, predlist, average='macro'))\n",
    "    # print(classification_report(labelist, predlist, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run # 0\n"
     ]
    }
   ],
   "source": [
    "maeelist = []\n",
    "wf1list = []\n",
    "mf1list = []\n",
    "\n",
    "for i in range(30):\n",
    "    print('Run #',i)\n",
    "    maee, wf1, mf1 = run_one_epoch('SupCon5')\n",
    "    print('MAEE', maee)\n",
    "    print('weight F1', wf1)\n",
    "    print('macro F1', mf1)\n",
    "    maeelist.append(maee)\n",
    "    wf1list.append(wf1)\n",
    "    mf1list.append(mf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.955012"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(torch.stack(maeelist).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.9301543, 7.4657617, 5.646627 , 6.8433857, 6.9685774, 5.713974 ,\n",
       "       6.8964286, 7.6229773, 6.103554 , 6.677058 , 6.3613834, 9.017594 ,\n",
       "       8.468648 , 7.057261 , 6.4172873, 7.20034  , 7.173798 , 6.867067 ,\n",
       "       7.908414 , 6.713133 , 7.919269 , 6.2424607, 6.862925 , 7.220572 ,\n",
       "       6.458567 , 5.816807 , 5.9272604, 6.387925 , 7.3420672, 7.4190793],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(maeelist).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45167458, 0.45852762, 0.52263185, 0.47129677, 0.47913616,\n",
       "       0.46798551, 0.44278422, 0.44287191, 0.46738576, 0.47117741,\n",
       "       0.45351873, 0.43029854, 0.45762693, 0.47775121, 0.48162963,\n",
       "       0.4750384 , 0.44859187, 0.45623733, 0.48501998, 0.48594605,\n",
       "       0.44047564, 0.45517946, 0.50051345, 0.436278  , 0.47776474,\n",
       "       0.46614189, 0.48867874, 0.49319403, 0.46397204, 0.40569602])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(wf1list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
