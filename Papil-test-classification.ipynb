{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "# from torchvision import models, transforms\n",
    "# import sys\n",
    "# import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "# import torch.functional as F\n",
    "import numpy as np\n",
    "clear_output()\n",
    "# import glob\n",
    "from utils import *\n",
    "from datetime import date\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from constants import mean, std\n",
    "from PapilledemaLoader import PapilledemaDataset, PapilSeverityDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(pretrain_mode = 'ConPro', mode = 0, epo = 0):\n",
    "    pretrain_mode = pretrain_mode\n",
    "\n",
    "    data_dir = '/mnt/c/Users/PCM/Dropbox/chla_fundus_croped/severity'\n",
    "    image_datasets = {x: PapilledemaDataset(data_dir=data_dir, phase=x) for x in ['test']}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4)\n",
    "                for x in ['test']}\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['test']}\n",
    "    class_names = image_datasets['test'].classes\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # print(device, class_names)\n",
    "\n",
    "    bestmodel = models.resnet50(weights='ResNet50_Weights.DEFAULT')#get_feature_extractor(feature_extractor='resnet50', cotrain=False)#, simclr='/mnt/c/Users/PCM/Documents/GitHub/pseudopapill/SimCLR/runs/Oct29_21-00-13_DESKTOP-404G4HS/checkpoint_95_29102023.pth.tar')\n",
    "    bestmodel.fc = nn.Sequential(torch.nn.Linear(2048, 1000),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    torch.nn.Dropout(0.1),\n",
    "                                    torch.nn.Linear(1000, 256),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    torch.nn.Dropout(0.1),\n",
    "                                    torch.nn.Linear(256, len(class_names)))\n",
    "    bestmodel.load_state_dict(torch.load(f'./pretrained/{pretrain_mode}/best{mode}-{pretrain_mode}-{epo}.pt'))\n",
    "    bestmodel.to(device)\n",
    "\n",
    "    test_acc = 0\n",
    "    predlist = []\n",
    "    labelist = []\n",
    "    problist = []\n",
    "    sedis = 0\n",
    "\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        bestmodel.eval()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = bestmodel(inputs)\n",
    "            # emb = fextractor(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            # loss = loss_fn(outputs, labels)\n",
    "            sedis = sedis + torch.sum(torch.exp(torch.abs(labels - torch.max(outputs, 1)[1])))\n",
    "        problist.append(outputs[:,1].detach().cpu().numpy())\n",
    "        labelist.append(labels.detach().cpu().numpy()*1)\n",
    "        predlist.append(preds.detach().cpu().numpy())\n",
    "        # test_embeddings  = torch.cat((test_embeddings, emb.detach().cpu().flatten().unsqueeze(0)), axis=0)\n",
    "        test_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "    labelist = np.concatenate(labelist).ravel()\n",
    "    problist = np.concatenate(problist).ravel()\n",
    "    predlist = np.concatenate(predlist).ravel()\n",
    "    return sedis/dataset_sizes['test'], recall_score(labelist, predlist, average='macro'), f1_score(labelist, predlist, average='macro')\n",
    "    # # print('MAEE', sedis/dataset_sizes['test'])\n",
    "    # # print('weight F1', f1_score(labelist, predlist, average='weighted'))\n",
    "    # # print('macro F1', f1_score(labelist, predlist, average='macro'))\n",
    "    # # print(classification_report(labelist, predlist, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run # 0\n",
      "Run # 1\n",
      "Run # 2\n",
      "Run # 3\n",
      "Run # 4\n",
      "Run # 5\n",
      "Run # 6\n",
      "Run # 7\n",
      "Run # 8\n",
      "Run # 9\n",
      "Run # 10\n",
      "Run # 11\n",
      "Run # 12\n",
      "Run # 13\n",
      "Run # 14\n",
      "Run # 15\n",
      "Run # 16\n",
      "Run # 17\n",
      "Run # 18\n",
      "Run # 19\n",
      "Run # 20\n",
      "Run # 21\n",
      "Run # 22\n",
      "Run # 23\n",
      "Run # 24\n",
      "Run # 25\n",
      "Run # 26\n",
      "Run # 27\n",
      "Run # 28\n",
      "Run # 29\n"
     ]
    }
   ],
   "source": [
    "maeelist = []\n",
    "reclist = []\n",
    "mf1list = []\n",
    "pretrain_model = 'ConPro20'\n",
    "for i in range(30):\n",
    "    print('Run #',i)\n",
    "    # maee, _, _ = run_test(pretrain_model, 'f1', i)\n",
    "    # _, acc, _ = run_test(pretrain_model, 'f1', i)\n",
    "    # _, _, mf1 = run_test(pretrain_model, 'f1', i)\n",
    "    maee, rec, mf1 = run_test(pretrain_model, 'f1', i)\n",
    "    # print('MAEE', maee)\n",
    "    # print('Precision', acc)\n",
    "    # print('macro F1', mf1)\n",
    "    maeelist.append(maee)\n",
    "    mf1list.append(mf1)\n",
    "    reclist.append(rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and std of F1 46.257317733907826 5.090398139076438\n",
      "mean and std of recall 47.525213675213685 4.301730684897399\n",
      "mean and std of maee 5.0820975 0.2906615\n"
     ]
    }
   ],
   "source": [
    "print('mean and std of F1', np.mean(mf1list)*100, np.std(mf1list)*100)\n",
    "print('mean and std of recall', np.mean(reclist)*100, np.std(reclist)*100)\n",
    "print('mean and std of maee', np.mean(torch.stack(maeelist).cpu().numpy()), np.std(torch.stack(maeelist).cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(5.2205, device='cuda:0'),\n",
       " tensor(4.7053, device='cuda:0'),\n",
       " tensor(4.7731, device='cuda:0'),\n",
       " tensor(5.4390, device='cuda:0'),\n",
       " tensor(4.8788, device='cuda:0'),\n",
       " tensor(4.5318, device='cuda:0'),\n",
       " tensor(4.7246, device='cuda:0'),\n",
       " tensor(4.8233, device='cuda:0'),\n",
       " tensor(4.5711, device='cuda:0'),\n",
       " tensor(4.6683, device='cuda:0'),\n",
       " tensor(4.6877, device='cuda:0'),\n",
       " tensor(5.1466, device='cuda:0'),\n",
       " tensor(4.7414, device='cuda:0'),\n",
       " tensor(4.4120, device='cuda:0'),\n",
       " tensor(5.0972, device='cuda:0'),\n",
       " tensor(4.9096, device='cuda:0'),\n",
       " tensor(4.4120, device='cuda:0'),\n",
       " tensor(4.6366, device='cuda:0'),\n",
       " tensor(5.0092, device='cuda:0'),\n",
       " tensor(5.2470, device='cuda:0'),\n",
       " tensor(4.6366, device='cuda:0'),\n",
       " tensor(4.7546, device='cuda:0'),\n",
       " tensor(4.8911, device='cuda:0'),\n",
       " tensor(4.3627, device='cuda:0'),\n",
       " tensor(5.0788, device='cuda:0'),\n",
       " tensor(4.9607, device='cuda:0'),\n",
       " tensor(4.5361, device='cuda:0'),\n",
       " tensor(5.1157, device='cuda:0'),\n",
       " tensor(4.8233, device='cuda:0'),\n",
       " tensor(4.7555, device='cuda:0')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maeelist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
