{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "# from torchvision import models, transforms\n",
    "# import sys\n",
    "# import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "# import torch.functional as F\n",
    "import numpy as np\n",
    "clear_output()\n",
    "# import glob\n",
    "from utils import *\n",
    "from datetime import date\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from constants import mean, std\n",
    "from PapilledemaLoader import PapilledemaDataset, PapilSeverityDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 ['0', '1', '2', '3', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/mnt/c/Users/PCM/Dropbox/chla_fundus_croped/severity'\n",
    "image_datasets = {x: PapilledemaDataset(data_dir=data_dir, phase=x) for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val',  'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load simclr resnet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestsmodel = SeverityModel().to(device)\n",
    "state_dict = torch.load('./pretrained/best-smodel50-wofreeze-2024-03-10.pt')\n",
    "bestsmodel.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestsmodel.bestsimese50simclr.cnn1.fc = torch.nn.Sequential(*(list(bestsmodel.bestsimese50simclr.cnn1.fc)+list(bestsmodel.bestsimese50simclr.cnn1.fc2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bestsmodel.bestsimese50simclr.cnn1.state_dict(), './pretrained/COPE-resnet50.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['fc.6.weight', 'fc.6.bias'], unexpected_keys=['fc2.0.weight', 'fc2.0.bias', 'fc2.3.weight', 'fc2.3.bias', 'fc.7.weight', 'fc.7.bias', 'fc.4.weight', 'fc.4.bias'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "clf_model.fc = nn.Sequential(torch.nn.Linear(2048, 1000),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Dropout(0.1),\n",
    "                                torch.nn.Linear(1000, 256),\n",
    "                                # torch.nn.Linear(256, 256),\n",
    "                                # torch.nn.ReLU(),\n",
    "                                # torch.nn.Dropout(0.1),\n",
    "                                # torch.nn.Linear(256, 256),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Dropout(0.1),\n",
    "                                torch.nn.Linear(256, len(class_names)))\n",
    "clf_model.load_state_dict(torch.load('./pretrained/COPE-resnet50.pt'), strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model = clf_model.to(device)\n",
    "momentum = 0.9\n",
    "lr = 0.01\n",
    "optimizer_ft = optim.SGD([{'params': clf_model.fc[:].parameters()}], lr=lr, momentum=momentum)\n",
    "class_weights=torch.tensor([0.3, 1.28, 1.51, 1.31, 3.18, 11],dtype=torch.float).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.5)\n",
    "\n",
    "for param in clf_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in clf_model.fc[:].parameters():\n",
    "    param.requires_grad = True\n",
    "# for param in clf_model.fc[8:].parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in clf_model.fc.parameters():\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0 With LR 0.01 training acc:  0.15201192250372578 Val acc:  0.4823529411764706 traning loss:  1.75893988143847\n",
      "E1 With LR 0.01 training acc:  0.518628912071535 Val acc:  0.6235294117647059 traning loss:  1.6051278446541457\n",
      "E2 With LR 0.01 training acc:  0.4247391952309985 Val acc:  0.4470588235294118 traning loss:  1.4595635491582923\n",
      "E3 With LR 0.01 training acc:  0.3472429210134128 Val acc:  0.24705882352941178 traning loss:  1.427533853427131\n",
      "E4 With LR 0.01 training acc:  0.3323397913561848 Val acc:  0.5882352941176471 traning loss:  1.4427800109240763\n",
      "E5 With LR 0.01 training acc:  0.46348733233979134 Val acc:  0.17647058823529413 traning loss:  1.3594312936111996\n",
      "E6 With LR 0.01 training acc:  0.4396423248882265 Val acc:  0.47058823529411764 traning loss:  1.317581879222091\n",
      "E7 With LR 0.01 training acc:  0.5081967213114754 Val acc:  0.2 traning loss:  1.2690132579220745\n",
      "E8 With LR 0.01 training acc:  0.5350223546944859 Val acc:  0.25882352941176473 traning loss:  1.2174207661439693\n",
      "E9 With LR 0.005 training acc:  0.5350223546944859 Val acc:  0.4588235294117647 traning loss:  1.2295746353806043\n",
      "E10 With LR 0.005 training acc:  0.5543964232488823 Val acc:  0.4 traning loss:  1.1459404853701414\n",
      "E11 With LR 0.005 training acc:  0.5514157973174366 Val acc:  0.5058823529411764 traning loss:  1.1728069956363047\n",
      "E12 With LR 0.005 training acc:  0.5931445603576752 Val acc:  0.47058823529411764 traning loss:  1.1227983403312467\n",
      "E13 With LR 0.005 training acc:  0.6020864381520119 Val acc:  0.49411764705882355 traning loss:  0.9991299954150011\n",
      "E14 With LR 0.005 training acc:  0.6080476900149031 Val acc:  0.2823529411764706 traning loss:  1.0547985347479183\n",
      "E15 With LR 0.005 training acc:  0.6035767511177347 Val acc:  0.4470588235294118 traning loss:  1.0441857773571896\n",
      "E16 With LR 0.005 training acc:  0.5961251862891207 Val acc:  0.49411764705882355 traning loss:  1.0572611153036933\n",
      "E17 With LR 0.005 training acc:  0.6318926974664679 Val acc:  0.4588235294117647 traning loss:  0.9508727044533333\n",
      "E18 With LR 0.005 training acc:  0.5946348733233979 Val acc:  0.35294117647058826 traning loss:  0.9821717784408308\n",
      "E19 With LR 0.0025 training acc:  0.6438152011922503 Val acc:  0.3764705882352941 traning loss:  0.9033697999003392\n",
      "E20 With LR 0.0025 training acc:  0.6229508196721312 Val acc:  0.4588235294117647 traning loss:  0.9318793944559225\n",
      "E21 With LR 0.0025 training acc:  0.6646795827123696 Val acc:  0.43529411764705883 traning loss:  0.9053597793138507\n",
      "E22 With LR 0.0025 training acc:  0.6199701937406855 Val acc:  0.4470588235294118 traning loss:  0.9072196713680659\n",
      "E23 With LR 0.0025 training acc:  0.6780923994038748 Val acc:  0.47058823529411764 traning loss:  0.8210577444241406\n",
      "E24 With LR 0.0025 training acc:  0.6497764530551415 Val acc:  0.4 traning loss:  0.8944715959659809\n",
      "E25 With LR 0.0025 training acc:  0.6587183308494784 Val acc:  0.4235294117647059 traning loss:  0.8830629177669121\n",
      "E26 With LR 0.0025 training acc:  0.6125186289120715 Val acc:  0.4823529411764706 traning loss:  0.9389596573464384\n",
      "E27 With LR 0.0025 training acc:  0.6915052160953801 Val acc:  0.36470588235294116 traning loss:  0.8204158992241463\n",
      "E28 With LR 0.0025 training acc:  0.6497764530551415 Val acc:  0.47058823529411764 traning loss:  0.8519654257997493\n",
      "E29 With LR 0.00125 training acc:  0.6140089418777943 Val acc:  0.4235294117647059 traning loss:  0.8782042716192595\n",
      "E30 With LR 0.00125 training acc:  0.6631892697466468 Val acc:  0.4117647058823529 traning loss:  0.9058949297124689\n",
      "E31 With LR 0.00125 training acc:  0.6855439642324889 Val acc:  0.4470588235294118 traning loss:  0.8294055893595279\n",
      "E32 With LR 0.00125 training acc:  0.646795827123696 Val acc:  0.4235294117647059 traning loss:  0.8807472276616558\n",
      "E33 With LR 0.00125 training acc:  0.6810730253353204 Val acc:  0.4117647058823529 traning loss:  0.7802410674255047\n",
      "E34 With LR 0.00125 training acc:  0.6676602086438153 Val acc:  0.4588235294117647 traning loss:  0.8187477926205949\n",
      "E35 With LR 0.00125 training acc:  0.6825633383010432 Val acc:  0.47058823529411764 traning loss:  0.8378833235642594\n",
      "E36 With LR 0.00125 training acc:  0.6900149031296572 Val acc:  0.5058823529411764 traning loss:  0.8215318705925465\n",
      "E37 With LR 0.00125 training acc:  0.6631892697466468 Val acc:  0.43529411764705883 traning loss:  0.8476410517927075\n",
      "E38 With LR 0.00125 training acc:  0.6572280178837556 Val acc:  0.4588235294117647 traning loss:  0.8216227028302393\n",
      "E39 With LR 0.000625 training acc:  0.6780923994038748 Val acc:  0.49411764705882355 traning loss:  0.9080965053484443\n",
      "E40 With LR 0.000625 training acc:  0.7093889716840537 Val acc:  0.49411764705882355 traning loss:  0.7650119041366122\n",
      "E41 With LR 0.000625 training acc:  0.6929955290611028 Val acc:  0.43529411764705883 traning loss:  0.7935299253321618\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      9\u001b[0m     clf_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 10\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# bestmodel = siamese50simclr\n",
    "valaccmax = 0\n",
    "for e in range(50):\n",
    "    training_acc = 0\n",
    "    val_acc = 0\n",
    "    training_loss_test = 0.0\n",
    "\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        clf_model.train()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ft.zero_grad()\n",
    "\n",
    "        outputs = clf_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        training_loss_test += loss.item() * inputs.size(0)\n",
    "        training_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "        clf_model.eval()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = clf_model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "        val_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "    if(e > 5 and val_acc > valaccmax):\n",
    "        valaccmax = val_acc\n",
    "        torch.save(clf_model.state_dict(), './pretrained/best-mutlclassclassification-siamese50COPE.pt')\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"E{e} With LR {optimizer_ft.param_groups[0]['lr']} training acc: \", training_acc.detach().cpu().numpy() / dataset_sizes['train'], \"Val acc: \", val_acc.detach().cpu().numpy() / dataset_sizes['val'], \"traning loss: \", training_loss_test / dataset_sizes['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=1000, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel = get_feature_extractor(feature_extractor='resnet50', cotrain=False)#, simclr='/mnt/c/Users/PCM/Documents/GitHub/pseudopapill/SimCLR/runs/Oct29_21-00-13_DESKTOP-404G4HS/checkpoint_95_29102023.pth.tar')\n",
    "\n",
    "bestmodel.fc = nn.Sequential(torch.nn.Linear(2048, 1000),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Dropout(0.1),\n",
    "                                torch.nn.Linear(1000, 256),\n",
    "                                # torch.nn.Linear(256, 256),\n",
    "                                # torch.nn.ReLU(),\n",
    "                                # torch.nn.Dropout(0.1),\n",
    "                                # torch.nn.Linear(256, 256),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Dropout(0.1),\n",
    "                                torch.nn.Linear(256, len(class_names)))\n",
    "bestmodel.load_state_dict(torch.load('./pretrained/best-mutlclassclassification-siamese50COPE.pt'))\n",
    "bestmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = 0\n",
    "predlist = []\n",
    "labelist = []\n",
    "problist = []\n",
    "test_embeddings = torch.zeros((0, 2048))\n",
    "sedis = 0\n",
    "fextractor = torch.nn.Sequential(*(list(clf_model.children())[:-1]))\n",
    "\n",
    "for inputs, labels in dataloaders['test']:\n",
    "    clf_model.eval()\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = clf_model(inputs)\n",
    "        emb = fextractor(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        sedis = sedis + torch.sum(torch.exp(torch.abs(labels - torch.max(outputs, 1)[1])))\n",
    "    problist.append(outputs[:,1].detach().cpu().numpy())\n",
    "    labelist.append(labels.detach().cpu().numpy()*1)\n",
    "    predlist.append(preds.detach().cpu().numpy())\n",
    "    # test_embeddings  = torch.cat((test_embeddings, emb.detach().cpu().flatten().unsqueeze(0)), axis=0)\n",
    "    test_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "labelist = np.concatenate(labelist).ravel()\n",
    "problist = np.concatenate(problist).ravel()\n",
    "predlist = np.concatenate(predlist).ravel()\n",
    "# test_embeddings = np.array(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8233, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sedis/dataset_sizes['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.683     0.560     0.615        50\n",
      "           1      0.250     0.444     0.320         9\n",
      "           2      0.308     0.333     0.320        12\n",
      "           3      0.429     0.462     0.444        13\n",
      "           4      0.571     0.667     0.615         6\n",
      "           5      1.000     0.667     0.800         3\n",
      "\n",
      "    accuracy                          0.516        93\n",
      "   macro avg      0.540     0.522     0.519        93\n",
      "weighted avg      0.560     0.516     0.531        93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(classification_report(labelist, predlist, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(labelist, predlist)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m y_test \u001b[38;5;241m=\u001b[39m (labelist)\n\u001b[1;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m(problist)\n\u001b[0;32m----> 5\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mroc_auc_score(y_test, y_pred), \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(fpr,tpr,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression, AUC=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(auc))\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1095\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    994\u001b[0m     {\n\u001b[1;32m    995\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m ):\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \n\u001b[1;32m   1008\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1095\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xai/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:804\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    802\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m--> 804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m    806\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    807\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "y_test = (labelist)\n",
    "y_pred =(problist)\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"Logistic Regression, AUC=\"+str(auc))\n",
    "plt.grid(linestyle='--')\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
